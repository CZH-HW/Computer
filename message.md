
[TOC]

# 消息队列

## 1. 什么是消息队列
这样的场景你一定不陌生：小王到 M 记点餐之后，服务员给了他一个号牌，并让他在柜台桌子前方等待叫号取餐。每个人都按照自己付款拿到的号牌顺序排队等叫号。即使店里人再多，也不会显得没有秩序。

在上述场景中，柜台其实就充当了一个消息队列。小王等生产者把订餐的消息发送到柜台即消息队列里，又从其中取了餐即消费了消息，可以说这就是消息队列的一个完整走向——消息被发送到队列中，又成功被消费者消费。

“消息队列”是在消息的传输过程中保存消息的容器，队列的主要目的是提供路由并保证消息的传递。如果发送消息时接收者不可用，消息队列会保留消息，直到可以成功地传递它。
<br>

消息队列，一般我们会简称它为`MQ(Message Queue)`

> 分解来看：队列`(Queue)`是一种先进先出的数据结构

![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/queue.png)

> 消息队列`MQ(Message Queue)`就可以简单理解为：把要传输的数据放在队列中

我们可以把消息队列比作是一个存放消息的容器，当我们需要使用消息的时候可以取出消息供自己使用
- 把数据放到消息队列叫做生产者(producer)
- 从消息队列里边取数据叫做消费者(consumer)
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/MQ_1.png)



> 消息队列是分布式系统中重要的组件，使用消息队列主要是为了通过异步处理提高系统性能和削峰、降低系统耦合性。目前使用较多的消息队列有`ActiveMQ`，`RabbitMQ`，`Kafka`，`RocketMQ`
<br>

## 2. 为什么要使用消息队列

使用消息队列主要有2点好处：
1. 降低系统耦合性（解耦）
2. 通过异步处理提高系统性能（削峰、减少响应所需时间）

#### 2.1 解耦

**如果模块之间不存在直接调用，那么新增模块或者修改模块就对其他模块影响较小，这样系统的可扩展性无疑更好一些。**

##### 2.1.1 举例1
- step1:
  现在我有一个系统 A，系统 A 可以产生一个`userId`
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/decoupling_1.png)
<br>

- step2: 
  然后，现在有系统 B 和系统 C 都需要这个`userId`去做相关的操作
  此时系统A给系统 B 和系统 C 传入userId这个值
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/decoupling_2.png)
伪代码可以如下所示：
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/decoupling_3.png)
结构图如下所示：
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/decoupling_4.png)
<br>

- step3: 
  ok，一切平安无事度过了几个天。  
  某一天，系统 B 的负责人告诉系统 A 的负责人，现在系统B的`SystemBNeed2do(String userId)`这个接口不再使用了，让系统 A 别去调它了。
  于是，系统A的负责人说 “好的，那我就不调用你了”，于是就把调用系统B接口的代码给删掉了：
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/decoupling_5.png)
<br>

- step4:
  又过了几天，系统 D 的负责人接了个需求，也需要用到系统 A 的`userId`，于是就跑去跟系统 A 的负责人说："老哥，我要用到你的`userId`，你调一下我的接口吧"
  于是系统 A 说："没问题的，这就搞"
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/decoupling_6.png)
  然后，系统 A 的代码如下
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/decoupling_7.png)
<br>

- step5:
  时间飞逝：
  又过了几天，系统 E 的负责人过来了，告诉系统 A，需要 userId。
  又过了几天，系统 B 的负责人过来了，告诉系统 A，还是重新掉那个接口吧。
  又过了几天，系统 F 的负责人过来了，告诉系统 A，需要 userId。  
  ……  
  于是系统 A 的负责人，每天都被这给骚扰着，改来改去，改来改去…….  
  还有另外一个问题，调用系统 C 的时候，如果系统 C 挂了，系统 A 还得想办法处理。如果调用系统 D 时，由于网络延迟，请求超时了，那系统 A 是反馈 fail 还是重试？？  
  最后，系统 A 的负责人，觉得隔一段时间就改来改去，没意思，于是就跑路了。 
<br>

- step6: 
  然后，公司招来一个大佬，大佬经过几天熟悉，上来就说：
  **将系统 A 的`userId`写到消息队列中，这样系统 A 就不用经常改动了**
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/decoupling_8.png)

系统 A 将`userId`写到消息队列中，系统 C 和系统 D 从消息队列中拿数据。这样有什么好处？

- 系统 A 只负责把数据写到队列中，谁想要或不想要这个数据(消息)，系统 A 一点都不关心。

- 即便现在系统 D 不想要`userId`这个数据了，系统B又突然想要`userId`这个数据了，都跟系统 A 无关，系统 A 一点代码都不用改。

- 系统 D 拿`userId`不再经过系统 A，而是从消息队列里边拿。系统 D 即便挂了或者请求超时，都跟系统 A 无关，只跟消息队列有关。

这样一来，系统 A 与系统 B、C、D 都解耦了。
<br>

##### 2.1.2 举例2
场景说明：订单库存系统
用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。如下图
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/decoupling_12.png)
传统做法的缺点：
- 订单系统与库存系统耦合
- 假如库存系统无法访问，则订单调用库存接口将失败，从而导致订单失败

引入消息队列后的方案：
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/decoupling_13.png)
- 订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功并继续处理下一个用户订单
- 库存系统：订阅下单的消息，采用`pull/push`的方式，获取下单信息，库存系统根据下单信息，进行库存操作
- 在下单时库存系统不能正常使用时，也不影响正常下单，**因为下单后，订单系统写入消息队列就不再关心其他的后续操作了**。实现订单系统与库存系统的应用解耦
<br>

##### 2.1.3 总结
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/decoupling_9.png)
1. 消息队列利用**发布-订阅**模式工作：消息发送者（生产者）发布消息，一个或多个消息接受者（消费者）订阅消息。
2. 消息发送者（生产者）和消息接受者（消费者）之间没有直接耦合，消息发送者将消息发送至分布式消息队列即结束对消息的处理，消息接受者从分布式消息队列获取该消息后进行后续处理，**并不需要知道该消息从何而来**。对新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的**可扩展性设计**。
3. 消息接受者对消息进行过滤、处理、包装后，构造成一个新的消息类型，将消息继续发送出去，等待其他消息接受者订阅该消息。因此**基于事件（消息对象）驱动的业务架构可以是一系列流程**。
4. 分布式：为了避免消息队列服务器宕机造成消息丢失，会将成功发送到消息队列的消息存储在消息生产者服务器上，等消息真正被消费者服务器处理后才删除消息。**在消息队列服务器宕机后，生产者服务器会选择分布式消息队列服务器集群中的其他服务器发布消息**。


- 备注：
  消息队列并不是只能利用**发布-订阅**模式工作，只不过在**解耦**这个特定业务环境下是使用**发布-订阅**模式的。
  除了**发布-订阅**模式，还有**点对点**订阅模式（一个消息只有一个消费者），另外这两种消息模型是 JMS 提供的，AMQP 协议还提供了 5 种消息模型。
<br>

#### 2.2 异步、削峰

##### 2.2.1 异步
场景说明：系统 A 还是直接调用系统 B、C、D，采用同步处理
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/asynchronous_1.png)
伪代码如下：
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/asynchronous_2.png)

假设系统A运算出`userId`具体的值需要50ms，
调用系统B的接口需要300ms，
调用系统C的接口需要300ms，
调用系统D的接口需要300ms。
那么这次请求就需要50+300+300+300=950ms

并且我们得知，系统 A 做的是主要的业务，而系统 B、C、D 是非主要的业务。
比如系统 A 处理的是订单下单，而系统 B 处理的是订单下单成功后发送一条短信告诉具体的用户此订单已成功，而系统 C 和系统 D 也是处理一些小事而已，这样就不需要同步处理了。

那么此时，为了提高用户体验和吞吐量，其实可以异步地调用系统 B、C、D 的接口。所以，我们可以弄成是这样的：
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/asynchronous_3.png)
- 系统A执行完了以后，将userId写到消息队列中，然后就直接返回了(至于其他的操作，则异步处理)。
- 本来整个请求需要用950ms(同步)，现在将调用其他系统接口异步化，从请求到返回只需要100ms(异步)

强弱依赖梳理，将非关键调用链路的操作异步化，提升整体系统的吞吐能力

##### 2.2.2 削峰
场景说明：现在我们每个月要搞一次大促，大促期间的并发可能会很高的，比如每秒 3000 个请求。假设我们现在有两台机器处理请求，并且每台机器只能每次处理 1000 个请求。
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/peak_clipping_1.png)

那多出来的 1000 个请求，可能就把我们整个系统给搞崩了…所以，有一种办法，我们可以写到消息队列中。
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/peak_clipping_2.png)

系统 B 和系统 C 根据自己能够处理的请求数去消息队列中拿数据，这样即便有每秒有 8000 个请求，那只是把请求放在消息队列中，去拿消息队列的消息由系统自己去控制，这样就不会把整个系统给搞崩。
消息队列相当于设置了流量缓冲池，可以让 B、C 系统按照自身吞吐能力进行消费，不被冲垮。

##### 2.2.3 实际应用场景
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/peak_clipping_3.png)

- 在不使用消息队列服务器的时候，用户的请求数据直接写入数据库，在高并发的情况下数据库压力剧增，使得响应速度变慢。
- 在使用消息队列之后，用户的请求数据发送给消息队列之后立即返回，再由消息队列的消费者进程从消息队列中获取数据，异步写入数据库。
- 由于消息队列服务器处理速度快于数据库（消息队列也比数据库有更好的伸缩性），因此响应速度得到大幅改善。

通过异步处理，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务。 
举例：在电子商务一些秒杀、促销活动中，合理使用消息队列可以有效抵御促销活动刚开始大量订单涌入对系统的冲击。如下图所示
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/peak_clipping_4.png)

- 注意：因为用户请求数据写入消息队列之后就立即返回给用户了，但是**请求数据在后续的业务校验、写数据库等操作中可能失败**。
因此使用消息队列进行异步处理之后，需要适当修改业务流程进行配合，比如用户在提交订单之后，订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单之后，甚至出库后，再通过电子邮件或短信通知用户订单成功，以免交易纠纷。这就类似我们平时手机订火车票和电影票。


## 3. 使用消息队列带来的一些问题

既然 MQ 是互联网分层架构中的解耦利器，那所有通讯都使用 MQ 岂不是很好? 这是一个严重的误区，调用与被调用的关系，是无法被 MQ 取代的。

1. 系统复杂性提高：加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！消息可靠性和重复性互为矛盾，消息不丢不重难以同时保证。
2. 系统可用性降低：系统可用性在某种程度上降低，为什么这样说呢？在加入MQ之前，你不用考虑消息丢失或者说MQ挂掉等等的情况，但是，引入MQ之后你就需要去考虑了！
3. 一致性问题：上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了!
4. 消息传递路径更长，延时会增加

举例：
用户登录场景，登录页面调用 passport 服务，passport 服务的执行结果直接影响登录结果，此处的“登录页面”与“passport服务”就必须使用调用关系，而不能使用 MQ 通信。

调用方实时依赖执行结果的业务场景，请使用调用，而不是 MQ。


## 4. 消息队列工作原理


#### 4.1 消息生产者、消息者、队列
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/MQ_principle_1.png)
- 消息生产者`Producer`：发送消息到消息队列。
- 消息消费者`Consumer`：从消息队列接收消息。
- `Broker`：概念来自与 Apache ActiveMQ，**指 MQ 的服务端，帮你把消息从发送端传送到接收端**。
- 消息队列`MQ`：一个先进先出的消息存储区域。消息按照顺序发送接收，一旦消息被消费处理，该消息将从队列中删除。

设计 Broker 的主要原因：

（1）消息的转储：在更合适的时间点投递，或者通过一系列手段辅助消息最终能送达消费机。

（2）规范一种范式和通用的模式，以满足解耦、最终一致性、错峰等需求。

（3）简单理解就是一个消息转发器，把一次 RPC 做成两次 RPC。发送者把消息投递到 broker，broker 再将消息转发一手到接收端。总结起来就是两次 RPC 加一次转储，如果要做消费确认，则是三次 RPC。

#### 4.2 两种消息模型
1. 点对点消息队列模型（ point to point， queue ）
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/MQ_principle_2.png)

特点：
（1）消息生产者向一个特定的队列发送消息，消息消费者从该队列中接收消息
（2）每个消息只有一个消费者（即一旦被消费，消息就不再在消息队列中)，消息不可以被重复消费
（3）消息的生产者和消费者可以不同时处于运行状态，在时间上没有依赖性
（4）每一个成功处理的消息都由消息消费者签收确认（Acknowledge）

消息的 ACK 确认机制：
- 为了**保证消息不丢失**
，消息队列提供了消息 Acknowledge 机制，即 ACK 机制
- 当 Consumer 确认消息已经被消费处理，发送一个 ACK 给消息队列，此时消息队列便可以删除这个消息了。
- 如果 Consumer 宕机/关闭，没有发送 ACK，消息队列将认为这个消息没有被处理，会将这个消息重新发送给其他的 Consumer 重新消费处理。

<br>

2. 发布订阅消息模型 - Topic

![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/MQ_principle_3.png)

发布订阅模型包含三个角色：
- 主题（Topic）
- 发布者（Publisher）
- 订阅者（Subscriber）
多个发布者将消息发送到 Topic,系统将这些消息传递给多个订阅者。

特点：
（1）每个消息可以有多个消费者，消息可以重复消费
（2）必须先订阅，再发送消息，而后接收订阅的消息，这个顺序必须保证
（3）发布者和订阅者之间有时间上的依赖性
（4）针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息
（5）为了消费消息，订阅者必须保持运行的状态。


由于是消费者被动接收推送，所以无需感知消息队列是否有待消费的消息！但是 Consumer1、Consumer2、Consumer3 由于机器性能不一样，所以处理消息的能力也会不一样，但消息队列却无法感知消费者消费的速度！

所以推送的速度成了发布订阅模式的一个问题！假设三个消费者处理速度分别是 8M/s、5M/s、2M/s，如果队列推送的速度为 5M/s，则 Consumer3 无法承受！

如果队列推送的速度为 2M/s，则 Consumer1、Consumer2 会出现资源的极大浪费！







3. 两种消息模型的区别：
点对点消息队列模型中消息不可以被重复消费，而发布订阅消息模型中消息可以重复被消费



#### 4.3 消息队列的




生产者消费者模型的实现
　　生产者是一堆线程，消费者是另一堆线程，内存缓冲区可以使用 List 数组队列，数据类型只需要定义一个简单的类就好。关键是如何处理多线程之间的协作。这其实也是多线程通信的一个范例。

　　在这个模型中，最关键就是内存缓冲区为空的时候消费者必须等待，而内存缓冲区满的时候，生产者必须等待。其他时候可以是个动态平衡。值得注意的是多线程对临界区资源的操作时候必须保证在读写中只能存在一个线程，所以需要设计锁的策略。





#### 4.4 消息的顺序性保证

基于Queue消息模型，利用FIFO先进先出的特性，可以保证消息的顺序性





#### 4.6 消息的同步和异步收发

同步：消息的收发支持同步收发的方式。

同时还有另一种同步方式：同步收发场景下，消息生产者和消费者双向应答模式，例如：张三写封信送到邮局中转站，然后李四从中转站获得信，然后在写一份回执信，放到中转站，然后张三去取，当然张三写信的时候就得写明回信地址

消息的接收如果以同步的方式(Pull)进行接收，如果队列中为空，此时接收将处于同步阻塞状态，会一直等待，直到消息的到达。

异步：消息的收发同样支持异步方式：异步发送消息，不需要等待消息队列的接收确认；异步接收消息，以Push的方式触发消息消费者接收消息。

#### 4.6 消息的事务支持

消息的收发处理支持事务，例如：在任务中心场景中，一次处理可能涉及多个消息的接收、处理，这处于同一个事务范围内，如果一个消息处理失败，事务回滚，消息重新回到队列中。

#### 4.7 最终一致性的设计思路

主要是用“记录”和“补偿”的方式。

本地事务维护业务变化和通知消息，一起落地，然后RPC到达broker，在broker成功落地后，RPC返回成功，本地消息可以删除。否则本地消息一直靠定时任务轮询不断重发，这样就保证了消息可靠落地broker。

broker往consumer发送消息的过程类似，一直发送消息，直到consumer发送消费成功确认。

我们先不理会重复消息的问题，通过两次消息落地加补偿，下游是一定可以收到消息的。然后依赖状态机版本号等方式做判重，更新自己的业务，就实现了最终一致性。

如果出现消费方处理过慢消费不过来，要允许消费方主动ack error，并可以与broker约定下次投递的时间。

对于broker投递到consumer的消息，由于不确定丢失是在业务处理过程中还是消息发送丢失的情况下，有必要记录下投递的IP地址。决定重发之前询问这个IP，消息处理成功了吗？如果询问无果，再重发。

事务：本地事务，本地落地，补偿发送。本地事务做的，是业务落地和消息落地的事务，而不是业务落地和RPC成功的事务。消息只要成功落地，很大程度上就没有丢失的风险。


10. 消息的持久化

消息的持久化，对于一些关键的核心业务来说是非常重要的，启用消息持久化后，消息队列宕机重启后，消息可以从持久化存储恢复，消息不丢失，可以继续消费处理。

11. 消息队列的高可用性

在实际生产环境中，使用单个实例的消息队列服务，如果遇到宕机、重启等系统问题，消息队列就无法提供服务了，因此很多场景下，我们希望消息队列有高可用性支持，例如

RabbitMQ的镜像集群模式的高可用性方案，ActiveMQ也有基于LevelDB+ZooKeeper的高可用性方案，以及Kafka的Replication机制等。











分布式消息服务的原理

在消息队列的基础上，稳定可靠的消息队列服务——分布式消息服务应运而生。分布式消息服务（Distributed Message Service，简称DMS）是一项基于高可用分布式集群技术的消息中间件服务，提供普通队列、有序队列、Kafka队列、RabbitMQ，兼容HTTP、TCP、AMQP协议，为分布式应用提供低延迟、高并发的异步通信机制。其生产和消费消息的示意图如下图所示

消息生产者即发送消息的一方，也叫消息发送者，发送消息到指定的消息队列中。生产者将消息M发送到队列中。消息M在队列中冗余分布，存在多个副本。

消费消息的一方，也叫消息接收者，通过调用消息服务的消费接口从队列中读取消息。消费者从队列中消费消息，获取到消息M。在消费者消费消息M期间，消息M仍然停留在队列中，但消息M从被消费开始的30秒内不能被该消费组再次消费，若在这30秒内没有被消费者确认消费完成，则DMS认为消息M未消费成功，将可以被继续消费。

消费者确认消息M消费完成，消息M将不能被该消费者所在消费组消费。消息M仍然保持在队列中，并且可以被其它消费组消费，消息在队列中的保留时间为至少72小时（除非队列被删除），72小时后将会被删除。












## 5. Kafka
Kafka是分布式的发布—订阅消息系统。它最初由LinkedIn(领英)公司发布，使用Scala语言编写，与2010年12月份开源，成为Apache的顶级项目。Kafka是一个高吞吐量的、持久性的、分布式发布订阅消息系统。它主要用于处理活跃的数据(登录、浏览、点击、分享、喜欢等用户行为产生的数据)。
三大特点：
1. 高吞吐量（生产消费）
   可以满足每秒百万级别消息的生产和消费。
2. 持久性（中间存储）
   有一套完善的消息存储机制，确保数据的高效安全的持久化。
3. 分布式（整体健壮性）
   基于分布式的扩展和容错机制；Kafka的数据都会复制到几台服务器上。当某一台故障失效时，生产者和消费者转而使用其它的机器。


### 基本组成

![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/kafka_1.png)
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/kafka_2.png)

主要由Producer、Consumer、Broker、Topic、Partition、

#### Broker
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/kafka_3.png)

Broker 是 Kafka 实例，每个服务器上有一个或多个 Kafka 的实例
可以简单地认为一台 kafka 服务器就是一个 broker，一个 Kafka 集群由多个 Broker 组成。
每个 Kafka 集群内的 Broker 都有一个不重复的编号，Broker-0、Broker-1 等…… 




#### Topic与Partition

- Topic：消息的主题，可以理解为消息的分类，Kafka 的数据就保存在 Topic。在每个 Broker 上都可以创建多个 Topic。

- Partition：Topic的分区，每个 Topic 可以有多个 Partition，每个 partition 又由一个一个消息组成。
        同一个 Topic 在不同的 Partition 的数据是不重复的，Partition 的表现形式就是一个一个的文件夹！
        Partition 的作用是做负载均衡，提高 Kafka 的吞吐量。


![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/kafka_4.png)







这样，消息就以一个个id的方式，组织起来。

- producer 选择一个 topic，生产消息，消息会通过分配策略 append 到某个 partition 末尾。
- consumer 选择一个 topic，通过 id 指定从哪个位置开始消费消息。消费完成之后保留 id，下次可以从这个位置开始继续消费，也可以从其他任意位置开始消费。



每个消息都被标识了一个递增序列号代表其进来的先后顺序，并按顺序存储在 partition 中。

并且 Partition 中的每条消息都被标记了一个 sequential id ,也就是 offset，并且存储的数据是可配置存储时间的。
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/kafka_5.png)


kafka为每个主题维护了分布式的分区(partition)日志文件，每个partition在kafka存储层面是append log。任何发布到此partition的消息都会被追加到log文件的尾部，在分区中的每条消息都会按照时间顺序分配到一个单调递增的顺序编号，也就是我们的offset,offset是一个long型的数字，我们通过这个offset可以确定一条在该partition下的唯一消息。在partition下面是保证了有序性，但是在topic下面没有保证有序性。





上面的 id 在 kafka 中称为 offset，这种组织和处理策略提供了如下好处：

1. 消费者可以根据需求，灵活指定 offset 消费。
2. 保证了消息不变性，为并发消费提供了线程安全的保证。每个 consumer 都保留自己的 offset ，互相之间不干扰，不存在线程安全问题。
3. 消息访问的并行高效性。每个 topic 中的消息被组织成多个 partition，partition 均匀分配到集群 server 中。生产、消费消息的时候，会被路由到指定 partition，减少竞争，增加了程序的并行能力。
4. 增加消息系统的可伸缩性。每个 topic 中保留的消息可能非常庞大，通过 partition 将消息切分成多个子消息，并通过负责均衡策略将 partition 分配到不同 server。这样当机器负载满的时候，通过扩容可以将消息重新均匀分配。
5. 保证消息可靠性。消息消费完成之后不会删除，可以通过重置 offset 重新消费，保证了消息不会丢失。
6. 灵活的持久化策略。可以通过指定时间段（如最近一天）来保存消息，节省 broker 存储空间。
7. 备份高可用性。消息以 partition 为单位分配到多个 server，并以 partition 为单位进行备份。备份策略为：1个leader 和N个 followers，leader 接受读写请求，followers 被动复制 leader。leader 和 followers 会在集群中打散，保证 partition 高可用。






























ConsumerGroup

每个Consumer属于一个特定的Consumer Group，一条消息可以发送到多个不同的Consumer Group，但是一个Consumer Group中只能有一个Consumer能够消费该消息





Replication：每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为 Leader。 在 Kafka 中默认副本的最大数量是 10 个，且副本的数量不能大于 Broker 的数量，Follower 和 Leader 绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。














#### producer

producer生产消息需要如下参数：
- topic：往哪个 topic 生产消息。
- partition：往哪个 partition 生产消息。
- key：根据该 key 将消息分区到不同 partition。
- message：消息。
![](https://github.com/CZH-HW/CloudImg/raw/master/Comp/kafka_6.png)














## 5. 待思考和补充
1.Client如何将消息可靠投递到MQ

Client发送消息给MQ——>MQ将消息持久化后，发送Ack消息给Client，此处有可能因为网络问题导致Ack消息无法发送到Client，那么Client在等待超时后，会重传消息——>Client收到Ack消息后，认为消息已经投递成功。

2.MQ如何将消息可靠投递到Client

1.MQ将消息push给Client（或Client来pull消息）

2.Client得到消息并做完业务逻辑

3.Client发送Ack消息给MQ，通知MQ删除该消息，此处有可能因为网络问题导致Ack失败，那么Client会重复消息，这里就引出消费幂等的问题；

4.MQ将已消费的消息删除